{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb8vdcoJRzAgZrdaGkNLag",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_webapp/blob/main/section_3/01_image_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kW_qXJVTjic"
      },
      "source": [
        "# 画像認識アプリ\n",
        "Streamlitを使い、画像を認識するアプリを作りましょう。  \n",
        "フレームワークにはPyTorchを、モデルにはResNetを使用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●ライブラリのインストール\n",
        "Streamlit、およびアプリの動作の確認に使用する「ngrok」をインストールします。"
      ],
      "metadata": {
        "id": "vRJCuxALcgkb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbqipzj3nCy4"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit==1.20.0 --quiet\n",
        "!pip install pyngrok==4.1.1 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit、およびngrokをインポートしておきます。  \n",
        "エラーが発生する場合は、「ランタイム」→「ランタイムを再起動」によりランタイムを再起動し、再びコードセルを上から順に実行しましょう。"
      ],
      "metadata": {
        "id": "husUkYy5dhZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "OsHcq-kaDwIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●「モデル」を扱うファイル\n",
        "画像認識のモデル「ResNet」を読み込み、予測を行うコードを「model.py」に書き込みます。  \n",
        "今回は、訓練済みのResNet-101を読み込みます。  \n",
        "ResNet-101は、深さが101層の畳み込みニューラル ネットワークです。  \n",
        "https://pytorch.org/vision/stable/generated/torchvision.models.resnet101.html  \n",
        "分類の各ラベルは「imagenet_classes.txt」に格納されているので、アップロードしておきましょう。"
      ],
      "metadata": {
        "id": "KoBcfQYBTUSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "# 以下を「model.py」に書き込み\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "net = models.resnet101(pretrained=True)  # 訓練済みのモデルを読み込み\n",
        "with open(\"imagenet_classes.txt\") as f:  # ラベルの読み込み\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "def predict(img):\n",
        "    # 以下の設定はこちらを参考に設定: https://pytorch.org/hub/pytorch_vision_resnet/\n",
        "    transform = transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(\n",
        "                                        mean=[0.485, 0.456, 0.406],\n",
        "                                        std=[0.229, 0.224, 0.225]\n",
        "                                        )\n",
        "                                    ])\n",
        "\n",
        "    # モデルへの入力\n",
        "    img = transform(img)\n",
        "    x = torch.unsqueeze(img, 0)  # バッチ対応\n",
        "\n",
        "    # 予測\n",
        "    net.eval()\n",
        "    y = net(x)\n",
        "\n",
        "    # 結果を返す\n",
        "    y_prob = torch.nn.functional.softmax(torch.squeeze(y))  # 確率で表す\n",
        "    sorted_prob, sorted_indices = torch.sort(y_prob, descending=True)  # 降順にソート\n",
        "    return [(classes[idx], prob.item()) for idx, prob in zip(sorted_indices, sorted_prob)]"
      ],
      "metadata": {
        "id": "nmZpJOe9p6GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●アプリのコード\n",
        "画像認識アプリのコードを、「app.py」に書き込みます。  \n",
        "ローカルからアップロード、もしくはWebカメラで撮影した画像ファイルに、何が映っているのかを判定します。  \n",
        "なお、Webカメラはngrokが発行したURLではセキュリティ上動作しないので、今回は動作を確認できません。"
      ],
      "metadata": {
        "id": "5fOtVgU5duPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# 以下を「app.py」に書き込み\n",
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from model import predict\n",
        "\n",
        "st.set_option(\"deprecation.showfileUploaderEncoding\", False)\n",
        "\n",
        "st.sidebar.title(\"画像認識アプリ\")\n",
        "st.sidebar.write(\"ResNetを使って何の画像かを判定します。\")\n",
        "\n",
        "st.sidebar.write(\"\")\n",
        "\n",
        "img_source = st.sidebar.radio(\"画像のソースを選択してください。\",\n",
        "                              (\"画像をアップロード\", \"カメラで撮影\"))\n",
        "if img_source == \"画像をアップロード\":\n",
        "    img_file = st.sidebar.file_uploader(\"画像を選択してください。\", type=[\"png\", \"jpg\"])\n",
        "elif img_source == \"カメラで撮影\":\n",
        "    img_file = st.camera_input(\"カメラで撮影\")\n",
        "\n",
        "if img_file is not None:\n",
        "    with st.spinner(\"推定中...\"):\n",
        "        img = Image.open(img_file)\n",
        "        st.image(img, caption=\"対象の画像\", width=480)\n",
        "        st.write(\"\")\n",
        "\n",
        "        # 予測\n",
        "        results = predict(img)\n",
        "\n",
        "        # 結果の表示\n",
        "        st.subheader(\"判定結果\")\n",
        "        n_top = 5  # 確率が高い順に5位まで返す\n",
        "        for result in results[:n_top]:\n",
        "            st.write(str(round(result[1]*100, 2)) + \"%の確率で\" + result[0] + \"です。\")\n",
        "\n",
        "        # 円グラフの表示\n",
        "        pie_labels = [result[0] for result in results[:n_top]]\n",
        "        pie_labels.append(\"others\")\n",
        "        pie_probs = [result[1] for result in results[:n_top]]\n",
        "        pie_probs.append(sum([result[1] for result in results[n_top:]]))\n",
        "        fig, ax = plt.subplots()\n",
        "        wedgeprops={\"width\":0.3, \"edgecolor\":\"white\"}\n",
        "        textprops = {\"fontsize\":6}\n",
        "        ax.pie(pie_probs, labels=pie_labels, counterclock=False, startangle=90,\n",
        "               textprops=textprops, autopct=\"%.2f\", wedgeprops=wedgeprops)  # 円グラフ\n",
        "        st.pyplot(fig)"
      ],
      "metadata": {
        "id": "Ntj_BU3bnJli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●Authtokenの設定\n",
        "ngrokで接続するために必要な「Authtoken」を設定します。  \n",
        "以下のコードの、  \n",
        "`!ngrok authtoken YourAuthtoken`  \n",
        "における  \n",
        "`YourAuthtoken`の箇所を、自分のAuthtokenに置き換えます。  \n",
        "Authtokenは、ngrokのサイトに登録すれば取得することができます。  \n",
        "https://ngrok.com/\n"
      ],
      "metadata": {
        "id": "j03EsJaHh4KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken YourAuthtoken"
      ],
      "metadata": {
        "id": "mTfmORj2Dn7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ●アプリの起動と動作確認\n",
        "streamlitの`run`コマンドでアプリを起動します。\n"
      ],
      "metadata": {
        "id": "CnobL05MkjB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/dev/null&  # 「&>/dev/null&」により、出力を非表示にしてバックグランドジョブとして実行"
      ],
      "metadata": {
        "id": "W0jXlMXWK0vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ngrokのプロセスを終了した上で、新たにポートを指定して接続します。  \n",
        "接続の結果、urlを取得できます。  \n",
        "ngrokの無料プランでは同時に1つのプロセスしか動かせないので、エラーが発生した場合は「ランタイム」→「セッションの管理」で不要なGoogle Colabのセッションを修了しましょう。  "
      ],
      "metadata": {
        "id": "W5RLCJ7Sl2x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()  # プロセスの修了\n",
        "url = ngrok.connect(port=\"8501\")  # 接続"
      ],
      "metadata": {
        "id": "v23ymsdLK3x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "urlを表示し、リンク先でアプリが動作することを確認します。"
      ],
      "metadata": {
        "id": "NZ0O_pNan57t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(url)"
      ],
      "metadata": {
        "id": "MIY7ositLAXC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}